{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9169472502805837\n",
      "0.8574635241301908\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from ipynb.fs.defs.EDA import binning\n",
    "\n",
    "train_df = pd.read_pickle(\"./pp_train.pkl\")\n",
    "x_dat = data_df.drop(columns = 'Survived')\n",
    "y_dat = data_df.Survived\n",
    "\n",
    "x_bin = binning(data_df, ('Age','Fare')).drop(columns = 'Survived')\n",
    "\n",
    "                \n",
    "models = [LogisticRegression(), SVC(), DecisionTreeClassifier(), RandomForestClassifier(), XGBClassifier()]\n",
    "param_grids =[\n",
    "    {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': np.logspace(-4, 4, 10),\n",
    "        'solver': ['liblinear']\n",
    "    },\n",
    "    {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'gamma': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    },\n",
    "    {\n",
    "        'max_depth': np.linspace(1, 32, 32, endpoint=True),\n",
    "        'min_samples_split': np.linspace(0.1, 1.0, 10, endpoint=True),\n",
    "        'min_samples_leaf': np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "    },\n",
    "    {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'min_samples_leaf': [1, 5, 10, 25],\n",
    "        'min_samples_split': [10, 12, 16, 18],\n",
    "        'n_estimators': [100, 700, 1500]\n",
    "    },\n",
    "    {\n",
    "        'learning_rate': [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "        'max_depth': [3, 4, 5, 6, 8, 10, 12, 15],\n",
    "        'min_child_weight': [1, 3, 5, 7],\n",
    "        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "        'colsample_bytree': [0.3, 0.4, 0.5, 0.7]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, model=None):                        \n",
    "        self.model = model\n",
    "        self.name = type(self.model).__name__\n",
    "    \n",
    "    def train_best(self, model, x_dat, y_dat, params, cv):\n",
    "        grid = GridSearchCV(model, param_grid=params, cv=cv)\n",
    "        grid.fit(x_dat,y_dat)\n",
    "        return grid.best_estimator_\n",
    "    \n",
    "    def score(self, x_dat, y_dat):\n",
    "        return cross_val_score(self.model, x_dat, y_dat, cv)\n",
    "    \n",
    "    def predict(self,x_to_pred):\n",
    "        y_pred = self.model.predict(x_to_pred)\n",
    "        return y_pred\n",
    "    \n",
    "    def save(self, path):\n",
    "        pickle.dump(self.model, open(path, 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(self.name, open(path, 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    @staticmethod\n",
    "    def load(path):\n",
    "        model_inst = Model()\n",
    "        model_inst.model = pickle.load(open(path, 'rb'))\n",
    "        model_inst.name = pickle.load(open(path, 'rb'))\n",
    "        return model_inst\n",
    "    \n",
    "    \n",
    "clf = models[4]\n",
    "params = param_grids[4]\n",
    "\n",
    "model = Model()\n",
    "model = model.train_best(model=clf, x_dat=x_dat, y_dat=y_dat, params=params, cv=5)\n",
    "\n",
    "model2 = Model()\n",
    "model2 = model2.train_best(model=clf, x_dat=x_bin, y_dat=y_dat, params=params, cv=5)\n",
    "#model.save(path ='/models')\n",
    "print(model.score(x_dat,y_dat))\n",
    "print(model2.score(x_bin,y_dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "datahub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
