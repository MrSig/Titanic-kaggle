{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src import visualization, utils, impute\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the test and train datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Name        891 non-null object\n",
      "Sex         891 non-null object\n",
      "Age         714 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Cabin       204 non-null object\n",
      "Embarked    889 non-null object\n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 69.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "encoded_df = train_df.apply(utils.Utils.map_apply, axis='columns').drop(columns=['Ticket','PassengerId'])\n",
    "full_dummy_df = pd.get_dummies(encoded_df,columns=['Pclass','Sex','Name','Embarked','Cabin'])\n",
    "cabin_dummy = pd.get_dummies(encoded_df, columns=['Pclass','Sex','Name','Embarked'])\n",
    "print(encoded_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding/one-hot encoding the categorical attributes of the full training dataset.\n",
    "Then doing the same but without one-hot encoding cabin as we're preparing to first predict the cabin level of the missing values(687 NaN values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "##### knn on  Cabin  #####\n",
      "   \n",
      "\n",
      "##### vecor features #####\n",
      "  ('Pclass_1', 'Pclass_2', 'Pclass_3')  \n",
      "\n",
      "##### SCORE #####\n",
      "  0.3480392156862745\n",
      "\n",
      " There are  687  estimated values\n"
     ]
    }
   ],
   "source": [
    "knn_model_cabin = impute.Impute.knn(cabin_dummy, 4, ('Pclass_1','Pclass_2','Pclass_3'), 'Cabin')[0]\n",
    "x_pred_cabin = impute.Impute.x_to_pred(cabin_dummy, ('Pclass_1','Pclass_2','Pclass_3'), 'Cabin')\n",
    "knn_cabin_pred = knn_model_cabin.predict(x_pred_cabin)\n",
    "\n",
    "print('\\n There are ',len(knn_cabin_pred), ' estimated values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict the 687 missing values by running a knn model with the passenger class attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "##### knn on  Cabin  #####\n",
      "   \n",
      "\n",
      "##### vecor features #####\n",
      "  ('Pclass_1', 'Pclass_2', 'Pclass_3')  \n",
      "\n",
      "##### SCORE #####\n",
      "  0.3480392156862745\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Name        891 non-null object\n",
      "Sex         891 non-null object\n",
      "Age         714 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Cabin       891 non-null object\n",
      "Embarked    889 non-null object\n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 69.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "encoded_df = train_df.apply(utils.Utils.map_apply, axis='columns').drop(columns=['Ticket','PassengerId'])\n",
    "full_dummy_df = pd.get_dummies(encoded_df,columns=['Pclass','Sex','Name','Embarked','Cabin'])\n",
    "\n",
    "cabin_dummy = pd.get_dummies(encoded_df, columns=['Pclass','Sex','Name','Embarked'])\n",
    "\n",
    "knn_model_cabin = impute.Impute.knn(cabin_dummy, 4, ('Pclass_1','Pclass_2','Pclass_3'), 'Cabin')[0]\n",
    "x_pred_cabin = impute.Impute.x_to_pred(cabin_dummy, ('Pclass_1','Pclass_2','Pclass_3'), 'Cabin')\n",
    "knn_cabin_pred = knn_model_cabin.predict(x_pred_cabin)\n",
    "\n",
    "cab_impute_df = impute.Impute.replace(encoded_df, knn_cabin_pred, 'Cabin')\n",
    "cab_impute_enc = cab_impute_df.apply(utils.Utils.map_apply, axis='columns')\n",
    "\n",
    "print(cab_impute_enc.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully impute the NaN cabin values with the estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "##### Lin. Reg. on  Age  #####\n",
      "   \n",
      "\n",
      "##### COEFFICIENTS #####\n",
      "  [ 7.87898514 10.3902856  -2.42587744 -1.25716393 -3.30674707  6.68291961\n",
      " -4.06806004  8.71707376  1.88203242  3.90980924  2.91791328]  \n",
      "\n",
      "##### IN RSCORE #####\n",
      "  0.35078705010509137  \n",
      "\n",
      "##### OUT RSCORE #####\n",
      "  0.307561656740402\n",
      " \n",
      "\n",
      "##### knn on  Embarked  #####\n",
      "   \n",
      "\n",
      "##### vecor features #####\n",
      "  ('Name_mr', 'Name_miss', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Cabin_B', 'Cabin_C', 'Cabin_D')  \n",
      "\n",
      "##### SCORE #####\n",
      "  0.6985376827896513\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Name        891 non-null object\n",
      "Sex         891 non-null object\n",
      "Age         891 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Cabin       891 non-null object\n",
      "Embarked    891 non-null object\n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 69.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "full_dummy_df = pd.get_dummies(cab_impute_enc, columns=['Pclass','Sex','Name','Embarked','Cabin'])\n",
    "\n",
    "reg_model_age = impute.Impute.reg(full_dummy_df, 5, ('Name_mr', 'Name_mrs', 'Name_miss','Parch','SibSp','Pclass_1','Pclass_3','Cabin_A','Cabin_C','Cabin_D','Cabin_E'), 'Age')[0]\n",
    "x_pred_age = impute.Impute.x_to_pred(full_dummy_df, ('Name_mr', 'Name_mrs', 'Name_miss','Parch','SibSp','Pclass_1','Pclass_3','Cabin_A','Cabin_C','Cabin_D','Cabin_E'), 'Age')\n",
    "reg_age_pred = reg_model_age.predict(x_pred_age)\n",
    "\n",
    "age_impute_df = impute.Impute.replace(cab_impute_df, reg_age_pred, 'Age')\n",
    "age_impute_enc = age_impute_df.apply(utils.Utils.map_apply, axis='columns')\n",
    "\n",
    "# impute embarked\n",
    "embarked_dummy = pd.get_dummies(age_impute_enc, columns=['Pclass','Sex','Name','Cabin'])\n",
    "\n",
    "knn_model_embarked = impute.Impute.knn(embarked_dummy, 4, ('Name_mr', 'Name_miss','Pclass_1','Pclass_2','Pclass_3','Cabin_B','Cabin_C','Cabin_D'), 'Embarked')[0]\n",
    "x_pred_embarked = impute.Impute.x_to_pred(embarked_dummy, ('Name_mr', 'Name_miss','Pclass_1','Pclass_2','Pclass_3','Cabin_B','Cabin_C','Cabin_D'), 'Embarked')\n",
    "knn_embarked_pred = knn_model_embarked.predict(x_pred_embarked)\n",
    "\n",
    "emb_impute_df = impute.Impute.replace(age_impute_df, knn_embarked_pred, 'Embarked')\n",
    "emb_impute_enc = emb_impute_df.apply(utils.Utils.map_apply, axis='columns')\n",
    "\n",
    "train_imputed_dummy = pd.get_dummies(emb_impute_enc, columns=['Pclass','Sex','Name','Embarked','Cabin'])\n",
    "\n",
    "print(emb_impute_enc.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying the same principal to the other attributes that are missing values, we end up with a fully imputed training dataset. Note that for the continous values, we used a regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 9 columns):\n",
      "Pclass      418 non-null int64\n",
      "Name        418 non-null object\n",
      "Sex         418 non-null object\n",
      "Age         332 non-null float64\n",
      "SibSp       418 non-null int64\n",
      "Parch       418 non-null int64\n",
      "Fare        417 non-null float64\n",
      "Cabin       91 non-null object\n",
      "Embarked    418 non-null object\n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 29.5+ KB\n",
      "None\n",
      " \n",
      "\n",
      "##### Lin. Reg. on  Fare  #####\n",
      "   \n",
      "\n",
      "##### COEFFICIENTS #####\n",
      "  [ -0.1993639    5.96135074  10.29931478  33.6756009  -14.11569503\n",
      " -19.55990587   2.47334176  -2.47334176   4.54783743   4.56596803\n",
      "  -2.07449568  -7.03930979   7.20742249  -2.70313742  -4.50428507\n",
      "   0.83410617  52.7394313   45.73630044  20.29734395  11.93133758\n",
      "  23.7039143   17.33781442]  \n",
      "\n",
      "##### IN RSCORE #####\n",
      "  0.4828960483351825  \n",
      "\n",
      "##### OUT RSCORE #####\n",
      "  0.4594993670233196\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 9 columns):\n",
      "Pclass      418 non-null int64\n",
      "Name        418 non-null object\n",
      "Sex         418 non-null object\n",
      "Age         418 non-null float64\n",
      "SibSp       418 non-null int64\n",
      "Parch       418 non-null int64\n",
      "Fare        418 non-null float64\n",
      "Cabin       418 non-null object\n",
      "Embarked    418 non-null object\n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 29.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "enc_test_df = test_df.apply(utils.Utils.map_apply, axis='columns').drop(columns=['Ticket','PassengerId'])\n",
    "test_dummy_df = pd.get_dummies(enc_test_df,columns=['Pclass'])\n",
    "print(enc_test_df.info())\n",
    "#impute cabin\n",
    "\n",
    "x_pred_cabin_test = impute.Impute.x_to_pred(test_dummy_df, ('Pclass_1','Pclass_2','Pclass_3'), 'Cabin')\n",
    "knn_cab_pred_test = knn_model_cabin.predict(x_pred_cabin_test)\n",
    "\n",
    "cab_impute_test_df = impute.Impute.replace(enc_test_df, knn_cab_pred_test, 'Cabin')\n",
    "\n",
    "cab_impute_test_enc = cab_impute_test_df.apply(utils.Utils.map_apply, axis='columns')\n",
    "cab_impute_test_d = pd.get_dummies(cab_impute_test_enc, columns=['Pclass','Sex','Name','Embarked','Cabin'])\n",
    "\n",
    "# impute age\n",
    "\n",
    "x_pred_age_test = impute.Impute.x_to_pred(cab_impute_test_d, ('Name_mr', 'Name_mrs', 'Name_miss','Parch','SibSp','Pclass_1','Pclass_3','Cabin_A','Cabin_C','Cabin_D','Cabin_E'), 'Age')\n",
    "reg_age_pred_test = reg_model_age.predict(x_pred_age_test)\n",
    "\n",
    "age_impute_test_df = impute.Impute.replace(cab_impute_test_enc, reg_age_pred_test, 'Age')\n",
    "age_impute_test_enc = age_impute_test_df.apply(utils.Utils.map_apply, axis='columns')\n",
    "age_impute_test_d = pd.get_dummies(age_impute_test_enc, columns=['Pclass','Sex','Name','Embarked','Cabin'])\n",
    "\n",
    "# impute fare using train data for the estimation\n",
    "\n",
    "reg_model_fare = impute.Impute.reg(train_imputed_dummy, 5, ('Age', 'SibSp', 'Parch', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n",
    "                                                      'Name_miss', 'Name_mr', 'Name_mrs', 'Name_staff', 'Embarked_C', 'Embarked_Q', 'Embarked_S',\n",
    "                                                      'Cabin_A', 'Cabin_B', 'Cabin_C', 'Cabin_D', 'Cabin_E', 'Cabin_F', 'Cabin_G') , 'Fare')[0]\n",
    "x_pred_fare = impute.Impute.x_to_pred(age_impute_test_d, ('Age', 'SibSp', 'Parch', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n",
    "                                                      'Name_miss', 'Name_mr', 'Name_mrs', 'Name_staff', 'Embarked_C', 'Embarked_Q', 'Embarked_S',\n",
    "                                                      'Cabin_A', 'Cabin_B', 'Cabin_C', 'Cabin_D', 'Cabin_E', 'Cabin_F', 'Cabin_G'), 'Fare')\n",
    "reg_fare_pred = reg_model_fare.predict(x_pred_fare)\n",
    "\n",
    "fare_impute_df = impute.Impute.replace(age_impute_test_enc, reg_fare_pred, 'Fare')\n",
    "fare_impute_enc = fare_impute_df.apply(utils.Utils.map_apply, axis='columns')\n",
    "print(fare_impute_enc.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the NaN values in the test set, we did the same as for the training set. Note that the models we used for the test set were trained on the training set as it contains more observations, therefore better predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "test_pp = pd.get_dummies(fare_impute_enc,columns=['Pclass','Sex','Name','Embarked','Cabin'])\n",
    "train_pp = pd.get_dummies(emb_impute_enc,columns=['Pclass','Sex','Name','Embarked','Cabin'])\n",
    "\n",
    "\n",
    "test_pp.loc[:,('Age','Fare')] = StandardScaler().fit_transform(test_pp.loc[:,('Age','Fare')])\n",
    "train_pp.loc[:,('Age','Fare')] = StandardScaler().fit_transform(train_pp.loc[:,('Age','Fare')])\n",
    "\n",
    "test_pp.to_pickle(\"./pp_test.pkl\")\n",
    "test_pp.to_csv(\"./pp_test.csv\")\n",
    "\n",
    "train_pp.to_pickle(\"./pp_train.pkl\")\n",
    "train_pp.to_csv(\"./pp_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to one-hot encode and scale the continuous attributes in both the test and train dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "datahub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
